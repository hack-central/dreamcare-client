[{"/home/runner/mind-palace-client/src/reportWebVitals.js":"1","/home/runner/mind-palace-client/src/views/Landing.js":"2","/home/runner/mind-palace-client/src/views/Home.js":"3","/home/runner/mind-palace-client/src/App.js":"4","/home/runner/mind-palace-client/src/index.js":"5"},{"size":364,"mtime":1612045610746,"results":"6","hashOfConfig":"7"},{"size":1213,"mtime":1612064492505,"results":"8","hashOfConfig":"7"},{"size":4357,"mtime":1612063474165,"results":"9","hashOfConfig":"7"},{"size":487,"mtime":1612063433514,"results":"10","hashOfConfig":"7"},{"size":500,"mtime":1612045610746,"results":"11","hashOfConfig":"7"},{"filePath":"12","messages":"13","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"1lney6p",{"filePath":"14","messages":"15","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"16","messages":"17","errorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"18"},{"filePath":"19","messages":"20","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"21","messages":"22","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/home/runner/mind-palace-client/src/reportWebVitals.js",[],"/home/runner/mind-palace-client/src/views/Landing.js",["23"],"/home/runner/mind-palace-client/src/views/Home.js",["24","25","26","27","28"],"import React, { useEffect, useState } from 'react';\nimport { Link } from 'react-router-dom';\nimport axios from 'axios';\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from 'react-speech-recognition';\nimport speak from '../assets/speak.svg';\n\nexport default function Home() {\n  const MAX_TIME = 120;\n  const HINTS_TIME = 30;\n  const { transcript, listening } = useSpeechRecognition();\n  const [timeLeft, setTimeLeft] = useState(MAX_TIME);\n  const [query, setQuery] = useState('');\n  const [textQuery, setTextQuery] = useState('');\n  const [audioBuffer, setAudioBuffer] = useState(undefined);\n  const [bars, setBars] = useState([]);\n  const [response, setResponse] = useState('Lets get started detective!');\n\n  const countdown = () => {\n    let timerDuration = MAX_TIME;\n    const timer = setInterval(() => {\n      if (timerDuration >= 0) {\n        timerDuration = timerDuration - 1;\n        setTimeLeft(timerDuration);\n      }\n    }, 1000);\n\n    return () => clearInterval(timer);\n  };\n\n  useEffect(() => {\n    const timer = setInterval(() => {\n      setQuery(transcript);\n    }, 1500);\n\n    return () => clearInterval(timer);\n  }, [transcript]);\n\n  useEffect(() => {\n    countdown();\n\n    const timer = setTimeout(() => {\n      //   history.push('/result');\n    }, MAX_TIME * 1000);\n\n    return () => clearTimeout(timer);\n    // eslint-disable-next-line react-hooks/exhaustive-deps\n  }, []);\n\n  useEffect(() => {\n    navigator.mediaDevices\n      .getUserMedia({ audio: true, video: false })\n      .then((stream) => {\n        if (stream) {\n          const context = new (window.AudioContext ||\n            window.webkitAudioContext)();\n          const source = context.createMediaStreamSource(stream);\n          const analyser = context.createAnalyser();\n          source.connect(analyser);\n\n          function renderFrame() {\n            requestAnimationFrame(renderFrame);\n            const frequencyData = new Float32Array(256);\n            analyser.getFloatTimeDomainData(frequencyData);\n            // console.log(frequencyData);\n            const bars = [];\n            for (let i = 0; i < 54; i++) {\n              const val = Math.abs(frequencyData[i]);\n              bars.push(`${val * 1000}%`);\n            }\n            setBars(bars);\n          }\n          renderFrame();\n        }\n      });\n  }, []);\n\n  useEffect(() => {\n    if (audioBuffer) {\n      const context = new AudioContext() || new window.webkitAudioContext();\n      context.decodeAudioData(audioBuffer, (buffer) => {\n        const bufferSource = context.createBufferSource();\n        bufferSource.buffer = buffer;\n        bufferSource.connect(context.destination);\n        bufferSource.start();\n      });\n\n      return () => context.close();\n    }\n  }, [audioBuffer]);\n\n  useEffect(() => {\n    (async () => {\n      if (query) {\n        const data = JSON.stringify({ queries: [query] });\n        const config = {\n          method: 'post',\n          url: 'https://o2fast2curious-kkpo.uc.r.appspot.com/intent/text',\n          headers: {\n            'Content-Type': 'application/json',\n          },\n          data: data,\n        };\n\n        const res = await axios(config);\n        if (res && res.data.success) {\n          const {\n            fulfillmentText,\n            outputAudio: { data },\n          } = res.data.data[0];\n          const arrBuffer = new Uint8Array(data).buffer;\n          setAudioBuffer(arrBuffer);\n          setResponse(fulfillmentText);\n        }\n      }\n    })();\n  }, [query]);\n  return (\n    <div className=\"journal-container\">\n      <div className=\"journal-column\">\n        <h3 className=\"speech-input\">{transcript}</h3>\n        <h1 className=\"speech-output\">\"{response}\"</h1>\n\n        <div className=\"voice-button\">\n          <button\n            className=\"voice-button-icon\"\n            onClick={() =>\n              SpeechRecognition.startListening({ language: 'en-IN' })\n            }\n          >\n            <img style={{ maxWidth: '40px' }} src={speak} alt=\"speak icon\" />\n          </button>\n        </div>\n        {listening && (\n          <div className=\"voice-coder\">\n            <Visualizer bars={bars} />\n          </div>\n        )}\n\n        \n      </div>\n\n      <div className=\"journal-column\">...</div>\n    </div>\n  );\n}\n\nconst Visualizer = ({ bars }) => {\n  return bars.map((bar, i) => <span id={`${i + 1}`} style={{ height: bar }} />);\n};\n","/home/runner/mind-palace-client/src/App.js",[],"/home/runner/mind-palace-client/src/index.js",[],{"ruleId":"29","severity":1,"message":"30","line":9,"column":7,"nodeType":"31","endLine":12,"endColumn":9},{"ruleId":"32","severity":1,"message":"33","line":2,"column":10,"nodeType":"34","messageId":"35","endLine":2,"endColumn":14},{"ruleId":"32","severity":1,"message":"36","line":11,"column":9,"nodeType":"34","messageId":"35","endLine":11,"endColumn":19},{"ruleId":"32","severity":1,"message":"37","line":13,"column":10,"nodeType":"34","messageId":"35","endLine":13,"endColumn":18},{"ruleId":"32","severity":1,"message":"38","line":15,"column":10,"nodeType":"34","messageId":"35","endLine":15,"endColumn":19},{"ruleId":"32","severity":1,"message":"39","line":15,"column":21,"nodeType":"34","messageId":"35","endLine":15,"endColumn":33},"jsx-a11y/alt-text","img elements must have an alt prop, either with meaningful text, or an empty string for decorative images.","JSXOpeningElement","no-unused-vars","'Link' is defined but never used.","Identifier","unusedVar","'HINTS_TIME' is assigned a value but never used.","'timeLeft' is assigned a value but never used.","'textQuery' is assigned a value but never used.","'setTextQuery' is assigned a value but never used."]